1.Why can data systems be considered as abstraction?
we use them all the time without thinking too much. When building an application, most engineers wouldn’t dream of 
writing a new data storage engine from scratch

2.What's the difference between a database and a message queue?
They have very different access patterns, which means different performance characteristics, and thus very different 
implementations. 

3.Why many applications nowdays have high demanding on new requirements?
A single tool can no longer meet all of its data processing and storage needs. Instead, the work is broken down into 
tasks that can be performed efficiently on a single tool

4.How do you create a new special-purpose data system?
When you combine several tools in order to provide a service, the service’s interface or application programming 
interface (API) usually hides those implementation details from clients. 

5.What would happen if a black hole swallows earth and all the servers on it?
Tolerance of that fault would require web hosting in space—good luck getting that budget item approved. So it only makes 
sense to talk about tolerating certain types of faults. 

6.Which are the operational advantages of systems that tolerate the loss of entire machines?
A single-server system requires planned downtime if you need to reboot the machine (to apply operating system security 
patches, for example), whereas a system that can tolerate machine failure can be patched one node at a time, 
without downtime of the entire system

7.Why faults are harder to anticipate?
 because they are correlated across nodes, they tend to cause many more system failures than uncorrelated hardware faults 

8.How do we make our systems reliable, in spite of unreliable humans? 
By combining the approaches of designing systems in a way that minimizes opportunities for error, Decoupling the places where 
people make the most mistakes from the places where they can cause failures, testing thoroughly at all levels, allowing quick
and easy recovery from human errors, setting up detailed and clear monitoring and Implement good management practices and training
and finally implementing good management practices and training.

9.If a system is reliable in the present, does that mean it will always be, why?
No. Because it can fail in degradation moslty represented on increasing load, if a big data system can now process hundreds 
and hundreds terabytes of information may be in the future will not be able to load and process thousands of petabytes this
is known as degradation.

10.What does the best choice of parameters depend on?
The architecture of your system: it may be requests per second to a web server, the ratio of reads to writes in a database, 
the number of simultaneously active users in a chat room.

11.What are the things we care when using batch processing?
The number of records we can process per second, or the total time it takes to run a job on a dataset of a certain size

12.Where is the scalable architecture built in?
It is built around assumptions of which operations will be common and which will be rare—the load parameters.


